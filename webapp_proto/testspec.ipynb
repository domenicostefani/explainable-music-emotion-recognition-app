{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f6864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y, sr = librosa.load(librosa.ex('trumpet'), duration=2.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d63f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sinusoid(duration,sample_rate = 48000):\n",
    "    \"\"\"Generate a sinusoid for the specified duration at 48kHz sample rate\"\"\"\n",
    "      # Hz\n",
    "    frequency = 440  # Hz (A4 note)\n",
    "    \n",
    "    # Generate time array\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    \n",
    "    # Generate sinusoid with some modulation to make it more interesting\n",
    "    waveform = np.sin(2 * np.pi * frequency * t) * np.exp(-t/20)  # Decaying sinusoid\n",
    "    \n",
    "    # Normalize to [-1, 1]\n",
    "    if len(waveform) > 0:\n",
    "        waveform = waveform / np.max(np.abs(waveform))\n",
    "    \n",
    "    return t, waveform\n",
    "\n",
    "sample_rate = 48000  # Hz\n",
    "time_data, waveform_data = generate_sinusoid(18.0, sample_rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c9861",
   "metadata": {},
   "outputs": [],
   "source": [
    "title= 'Sinusoid Waveform'\n",
    "\n",
    "\n",
    "\n",
    "slice_id = 1\n",
    "\n",
    "sliceDuration = 3  # seconds\n",
    "sample_rate = 48000\n",
    "\n",
    "# Calculate slice boundaries\n",
    "start_sample = slice_id * sliceDuration * sample_rate\n",
    "end_sample = min((slice_id + 1) * sliceDuration * sample_rate, len(time_data))\n",
    "\n",
    "# Extract slice data\n",
    "slice_time = time_data[start_sample:end_sample+1]\n",
    "slice_waveform = waveform_data[start_sample:end_sample+1]\n",
    "\n",
    "# Adjust time to start from 0 for the slice\n",
    "# slice_time = slice_time - slice_time[0]\n",
    "\n",
    "print(f\"Slice {slice_id}: Time range {slice_time[0]:.2f} to {slice_time[-1]:.2f} seconds, \"\n",
    "      f\"Waveform length: {len(slice_waveform)} samples\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 2))\n",
    "\n",
    "S = librosa.feature.melspectrogram(y=slice_waveform, sr=sample_rate, n_mels=128, fmax=24000)\n",
    "S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "img = librosa.display.specshow(S_dB, sr=sample_rate, x_axis='time', y_axis='mel', ax=ax, cmap='magma')\n",
    "if (title):\n",
    "    ax.set_title(title)\n",
    "ax.set_xlabel('Time (seconds)')\n",
    "ax.set_ylabel('Frequency (Hz)')\n",
    "# plt.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "\n",
    "# Set x labels and ticks to match the time data passed\n",
    "zerobased_time = slice_time - slice_time[0]  # Adjust time to start from 0\n",
    "XAX_FACTOR = 5\n",
    "ax.set_xticks(zerobased_time[::int(len(zerobased_time)/sliceDuration/XAX_FACTOR)])  # Show 10 ticks\n",
    "ax.set_xticklabels([f\"{t:.1f}\" for t in slice_time[::int(len(slice_time)/sliceDuration/XAX_FACTOR)]], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db9db55",
   "metadata": {},
   "source": [
    "# Test display emotions per slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b361674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emotions\n",
    "import librosa, os\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import base64\n",
    "import numpy as np\n",
    "\n",
    "emotionClassifier = emotions.EmotionClassifier(\"../classifier/best_model_1_acc_53.14.h5\")\n",
    "\n",
    "# load file webapp_proto\\recordings\\recording_20250624_121056.wav\n",
    "CLASSIFIER_SR = 22050  # Sample rate for the classifier\n",
    "HIGH_SAMPLE_RATE = 48000  # High sample rate for the original audio\n",
    "\n",
    "FILENAME = 'recordings/recording_20250624_115335.wav'\n",
    "assert FILENAME.endswith('.wav'), \"File must be a .wav file\"\n",
    "assert os.path.exists(FILENAME), f\"File {FILENAME} does not exist\"\n",
    "\n",
    "waveform_data, sr = librosa.load(FILENAME, sr=HIGH_SAMPLE_RATE)\n",
    "lores_waveform_data, sr = librosa.load(FILENAME, sr=CLASSIFIER_SR)\n",
    "\n",
    "\n",
    "mels, segments, startstop = emotions.split_song(lores_waveform_data,\n",
    "                                    sampling_rate=CLASSIFIER_SR,\n",
    "                                    segment_duration_s=3,\n",
    "                                    overlap=0)\n",
    "\n",
    "pred_segment_emotions = []\n",
    "for mel_rgb_batch in mels:\n",
    "    # Predict emotions using the classifier\n",
    "    pred_emotion_label, pred_probabilities = emotionClassifier.predict_segment(mel_rgb_batch)\n",
    "    # print('shape of pred_emotion_label:', np.shape(pred_emotion_label))\n",
    "    # print('shape of pred_probabilities:', np.shape(pred_probabilities))\n",
    "    print(\"\", flush=True)\n",
    "\n",
    "    pred_emotions_dict = {emotion: prob for emotion, prob in zip(emotions.EMOTIONS, pred_probabilities)}\n",
    "\n",
    "    pred_segment_emotions.append((pred_emotion_label, pred_emotions_dict))  # Store both emotion and probabilities\n",
    "\n",
    "overall_emotion, overall_probabilities = emotionClassifier.majority_vote([e[1] for e in pred_segment_emotions])\n",
    "print(f\"Overall emotion: {overall_emotion}, Probabilities: {overall_probabilities}\")\n",
    "\n",
    "\n",
    "emotionLabels = [emotion[0] for emotion in pred_segment_emotions]\n",
    "emotionProbabilities = [emotion[1] for emotion in pred_segment_emotions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_segment_emotions = [emotions.randomEmotion() for e in range(len(segments))]\n",
    "\n",
    "emotionLabels = [emotion[0] for emotion in pred_segment_emotions]\n",
    "emotionProbabilities = [emotion[1] for emotion in pred_segment_emotions]\n",
    "pred_segment_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398eedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_waveform_plot(time_data, waveform_data, emotionLabels=None, emotionProbabilities=None, title=None, highlight_slice=None,figure_size=(12, 6), display=True, sliceDuration=3, sliceStart=0, simple=False):\n",
    "    \"\"\"Create a waveform plot and return as base64 encoded image\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figure_size)\n",
    "    ax.plot(time_data, waveform_data, 'b-', linewidth=0.5)\n",
    "    ax.set_xlabel('Time (seconds)')\n",
    "    if highlight_slice is not None:\n",
    "        plt.ylabel('Amplitude')\n",
    "    else:\n",
    "        # Remove yticks\n",
    "        ax.set_yticks([])  # Hide y-axis ticks\n",
    "\n",
    "    printVerbose = lambda *args, **kwargs: None  # Placeholder for verbose output\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    if not simple:\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    # maxw, minw = np.max(np.abs(waveform_data)), np.min(np.abs(waveform_data))\n",
    "    # maxw = max(maxw, 1e-6)\n",
    "    # minw = min(minw, -1e-6)\n",
    "    # maxw = max(abs(maxw), abs(minw))\n",
    "    # minw = -maxw\n",
    "    minw, maxw = (-1.0, 1.0)  # Fixed range for better visualization\n",
    "\n",
    "    # ax.set_ylim(-1.1, 1.1)\n",
    "    if not simple:\n",
    "        ax.set_ylim(minw*1.1, maxw*1.1)\n",
    "\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    # print(f\"x_min: {x_min}, x_max: {x_max}\")\n",
    "    trans = ax.transData.transform\n",
    "    sliceBoundaries = []\n",
    "    \n",
    "    if emotionLabels is not None:\n",
    "        assert emotionProbabilities is not None, \"Emotion probabilities must be provided if emotion labels are given\"\n",
    "        assert len(emotionLabels) == len(emotionProbabilities), \"Emotion labels and probabilities must have the same length\"\n",
    "        # get pixel boundaries for each emotion label\n",
    "        right_bound_pixel, _ = trans((x_max, 0))\n",
    "        left_bound_pixel, _ = trans((x_min, 0))\n",
    "        for i, (label, probabilities) in enumerate(zip(emotionLabels, emotionProbabilities)):\n",
    "            assert len(probabilities) == len(emotions.EMOTIONS), \"Probabilities must match the number of emotions\"\n",
    "            time_left = i * 3  # 3 seconds per slice\n",
    "            time_right = (i + 1) * 3\n",
    "            slice_left, _ = trans((time_left, 0))\n",
    "            slice_right, _ = trans((time_right, 0))\n",
    "\n",
    "            def floatMap (x, in_min, in_max, out_min, out_max):\n",
    "                \"\"\"Map a float from one range to another\"\"\"\n",
    "                return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n",
    "\n",
    "            relative_left_px = floatMap(slice_left, left_bound_pixel, right_bound_pixel, 0, 1)\n",
    "            relative_right_px = floatMap(slice_right, left_bound_pixel, right_bound_pixel, 0, 1)\n",
    "            sliceBoundaries.append((relative_left_px, relative_right_px))\n",
    "\n",
    "        # Add slice boundaries and labels for full waveform\n",
    "        if highlight_slice is None and len(time_data) > 0 and not simple:\n",
    "            duration = time_data[-1]\n",
    "            num_slices = len(emotionLabels)\n",
    "\n",
    "            printVerbose(f\"Duration: {duration}, Slice Duration: {sliceDuration}, Number of Slices: {num_slices}\")\n",
    "            \n",
    "            for i in range(0, num_slices+1):\n",
    "                slice_time = i * sliceDuration + sliceStart\n",
    "                if slice_time < duration:\n",
    "                    ax.axvline(x=slice_time, color='r', linestyle='--', alpha=0.6)\n",
    "            \n",
    "            # Add slice labels\n",
    "            for i in range(num_slices):\n",
    "                slice_start = i * sliceDuration\n",
    "                slice_center = slice_start + sliceDuration / 2\n",
    "                if slice_center < duration:\n",
    "                    label = emotionLabels[i] if i < len(emotionLabels) else \"Unknown\"\n",
    "                    printVerbose('emotionProbabilities[i]', emotionProbabilities[i])\n",
    "                    textlabel = emotionLabels[i]+\" %.1f%%\"%(emotionProbabilities[i][emotionLabels[i]]*100) if emotionLabels else \"\"\n",
    "                    printVerbose('emotions.EMOTIONS_TO_COLOR',emotions.EMOTIONS_TO_COLOR)\n",
    "                    printVerbose('label',label)\n",
    "                    printVerbose('label in emotions.EMOTIONS_TO_COLOR.keys():', label in emotions.EMOTIONS_TO_COLOR.keys())\n",
    "                    facecolor = emotions.EMOTIONS_TO_COLOR[label] if label in emotions.EMOTIONS_TO_COLOR.keys() else 'lightgrey'\n",
    "                    plt.text(slice_center, 0.9, textlabel, ha='center', va='center', \n",
    "                            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=facecolor, alpha=0.7),\n",
    "                            fontsize=14, fontweight='bold')\n",
    "                \n",
    "    # // xticks every sliceDuration/2, starting from sliceStart\n",
    "    x_ticks = np.arange(max(sliceStart, time_data[0]), time_data[-1]*1.1, sliceDuration/2.0)\n",
    "    ax.set_xticks(x_ticks)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if display:\n",
    "        plt.show()\n",
    "    # Convert plot to base64 string\n",
    "    img = io.BytesIO()\n",
    "    plt.savefig(img, format='png', dpi=100, bbox_inches='tight')\n",
    "    img.seek(0)\n",
    "    plot_url = base64.b64encode(img.getvalue()).decode()\n",
    "    plt.close()\n",
    "    \n",
    "    return plot_url, sliceBoundaries, (fig, ax)\n",
    "\n",
    "duration = len(waveform_data) / HIGH_SAMPLE_RATE\n",
    "time_data = np.linspace(0, duration, len(waveform_data))\n",
    "\n",
    "plot_url, sliceBoundaries, (fig,ax) = create_waveform_plot(time_data, waveform_data, emotionLabels, emotionProbabilities, display=True, simple=True, figure_size=(12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d971740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract slice data\n",
    "\n",
    "start_sample = 3 * HIGH_SAMPLE_RATE\n",
    "end_sample = min(6 * HIGH_SAMPLE_RATE, len(time_data))\n",
    "\n",
    "slice_time = time_data[start_sample:end_sample]\n",
    "slice_waveform = waveform_data[start_sample:end_sample]\n",
    "\n",
    "\n",
    "# Create zoomed plot\n",
    "slice_label = chr(ord('A') + slice_id)\n",
    "plot_url = create_waveform_plot(\n",
    "    slice_time, \n",
    "    slice_waveform, \n",
    "    title=f\"Audio Waveform - Slice {slice_label} (Zoomed)\",\n",
    "    highlight_slice=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "def plot_emotion_graph(emotionProbabilities, startstop, figure_size=(12, 6), display=False, smooth=True):\n",
    "    sample2Seconds = lambda x: x / CLASSIFIER_SR\n",
    "    startstop_s = [(sample2Seconds(start), sample2Seconds(stop)) for start, stop in startstop]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figure_size)\n",
    "\n",
    "    # points should be a dict with a key per each emotion, and the value is a list of tuples (time, probability)\n",
    "    points = {}\n",
    "    for d, (start, stop) in zip(emotionProbabilities, startstop_s):\n",
    "        for emotion, prob in d.items():\n",
    "            if emotion not in points:\n",
    "                points[emotion] = []\n",
    "            # Calculate the time for this segment (center of segment)\n",
    "            segment_time = (start + stop) / 2\n",
    "            points[emotion].append((segment_time, prob))\n",
    "\n",
    "    # Get the overall time range\n",
    "    if startstop_s:\n",
    "        overall_start = min(start for start, _ in startstop_s)\n",
    "        overall_end = max(stop for _, stop in startstop_s)\n",
    "    else:\n",
    "        overall_start, overall_end = 0, 1\n",
    "\n",
    "    # Create lines for each emotion (smooth or simple)\n",
    "    for emotion, pts in points.items():\n",
    "        if len(pts) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Sort points by time\n",
    "        pts = sorted(pts, key=lambda x: x[0])\n",
    "        point_times, point_probs = zip(*pts)\n",
    "        \n",
    "        emotion_capitalized = emotion.capitalize()\n",
    "        color = emotions.EMOTIONS_TO_COLOR.get(emotion, 'lightgrey')\n",
    "        \n",
    "        if smooth and len(pts) >= 2:\n",
    "            # Smooth interpolated lines\n",
    "            # Extend the line to cover the full time range\n",
    "            # Add points at the beginning and end with the same probability as the first/last points\n",
    "            extended_times = [overall_start] + list(point_times) + [overall_end]\n",
    "            extended_probs = [point_probs[0]] + list(point_probs) + [point_probs[-1]]\n",
    "            \n",
    "            # Create interpolation function\n",
    "            # Use 'cubic' for smooth curves, 'linear' for straight lines between points\n",
    "            try:\n",
    "                interp_func = interp1d(extended_times, extended_probs, kind='cubic', \n",
    "                                     bounds_error=False, fill_value='extrapolate')\n",
    "            except:\n",
    "                # Fall back to linear interpolation if cubic fails\n",
    "                interp_func = interp1d(extended_times, extended_probs, kind='linear', \n",
    "                                     bounds_error=False, fill_value='extrapolate')\n",
    "            \n",
    "            # Generate smooth time series for plotting\n",
    "            smooth_times = np.linspace(overall_start, overall_end, 200)\n",
    "            smooth_probs = interp_func(smooth_times)\n",
    "            \n",
    "            # Clip probabilities to [0, 1] range\n",
    "            smooth_probs = np.clip(smooth_probs, 0, 1)\n",
    "            \n",
    "            # Plot the smooth line\n",
    "            ax.plot(smooth_times, smooth_probs, \n",
    "                   label=emotion_capitalized, \n",
    "                   color=color, \n",
    "                   linewidth=2, alpha=0.8)\n",
    "            \n",
    "            # Plot the original data points\n",
    "            ax.scatter(point_times, point_probs, \n",
    "                      alpha=0.7, \n",
    "                      color=color,\n",
    "                      s=30, zorder=5)\n",
    "        else:\n",
    "            # Simple lines connecting points directly\n",
    "            # Add start and end points to extend the line\n",
    "            start_time, start_prob = pts[0]\n",
    "            end_time, end_prob = pts[-1]\n",
    "            extended_times = [overall_start] + list(point_times) + [overall_end]\n",
    "            extended_probs = [start_prob] + list(point_probs) + [end_prob]\n",
    "            \n",
    "            # Plot simple line\n",
    "            ax.plot(extended_times, extended_probs, \n",
    "                   linestyle='--', \n",
    "                   label=emotion_capitalized, \n",
    "                   color=color, \n",
    "                   linewidth=1, alpha=0.8)\n",
    "            \n",
    "            # Plot the original data points\n",
    "            ax.scatter(point_times, point_probs, \n",
    "                      alpha=0.5, \n",
    "                      color=color)\n",
    "\n",
    "    # Set x-axis ticks\n",
    "\n",
    "    xticks = np.arange(overall_start, overall_end + 1, 3)\n",
    "    ax.set_xticks(xticks, [f\"{t:.1f}\" for t in xticks], rotation=45)\n",
    "\n",
    "    # Add vertical dashed lines for each segment\n",
    "    for start, end in startstop_s:\n",
    "        ax.axvline(x=start, color='gray', linestyle='--', alpha=0.3, linewidth=0.8)\n",
    "        ax.axvline(x=end, color='gray', linestyle='--', alpha=0.3, linewidth=0.8)\n",
    "\n",
    "    ax.set_xlabel('Time (seconds)')\n",
    "    ax.set_ylabel('Emotion Probability')\n",
    "    # ax.set_ylim(0, 1)  # Ensure y-axis covers full probability range\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if display:\n",
    "        plt.show()\n",
    "    \n",
    "    # Convert plot to base64 string\n",
    "    img = io.BytesIO()\n",
    "    plt.savefig(img, format='png', dpi=100, bbox_inches='tight')\n",
    "    img.seek(0)\n",
    "    plot_url = base64.b64encode(img.getvalue()).decode()\n",
    "    plt.close()\n",
    "\n",
    "    return plot_url\n",
    "\n",
    "emotionGraphUrl = plot_emotion_graph(emotionProbabilities, startstop, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab89610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform_data, sr\n",
    "\n",
    "# Take first segment \n",
    "SEGMENT = 0\n",
    "# Extract the first segment of the waveform data\n",
    "segment_duration = 3  # seconds\n",
    "start_sample = SEGMENT * segment_duration * CLASSIFIER_SR\n",
    "end_sample = min((SEGMENT + 1) * segment_duration * CLASSIFIER_SR, len(waveform_data))\n",
    "slice_waveform = waveform_data[start_sample:end_sample]\n",
    "slice_time = np.linspace(SEGMENT * segment_duration, (SEGMENT + 1) * segment_duration, len(slice_waveform))\n",
    "\n",
    "sampling_rate=22050\n",
    "n_fft=2048\n",
    "hop_length=512\n",
    "n_mels=128\n",
    "\n",
    "mel = librosa.feature.melspectrogram(y=slice_waveform, sr=CLASSIFIER_SR, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "mel_db_norm = ( mel_db - mel_db.min() ) / ( mel_db.max() - mel_db.min() )  # normalize 0-1\n",
    "mel_db_norm\n",
    "# librosa.display.specshow(mel_db_norm, sr=CLASSIFIER_SR, y_axis='mel', hop_length=hop_length, fmax=CLASSIFIER_SR/2)\n",
    "\n",
    "\n",
    "# melbin = 127\n",
    "# hz= emotions.mel_bin_to_hz(1,128)\n",
    "# hz*2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
